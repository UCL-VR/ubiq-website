<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Blog on</title><link>https://ucl-vr.github.io/ubiq-website/blog/</link><description>Recent content in Blog on</description><generator>Hugo -- gohugo.io</generator><language>en-US</language><lastBuildDate>Wed, 06 Oct 2021 08:49:55 +0000</lastBuildDate><atom:link href="https://ucl-vr.github.io/ubiq-website/blog/index.xml" rel="self" type="application/rss+xml"/><item><title>Ubiq and Ubiq-Genie Tutorial at IEEE VR 2026</title><link>https://ucl-vr.github.io/ubiq-website/blog/ubiq-and-ubiq-genie-tutorial-at-ieee-vr-2026/</link><pubDate>Mon, 05 Jan 2026 09:19:42 +0100</pubDate><guid>https://ucl-vr.github.io/ubiq-website/blog/ubiq-and-ubiq-genie-tutorial-at-ieee-vr-2026/</guid><description>Full sets of slides and video of the tutorial will be available after IEEE VR 2026. Summary In this tutorial we will explore how to build a wide variety of collaborative extended reality (XR) systems using the Ubiq software and then extend them to support artificial-intelligence (AI) based processes using Ubiq-Genie. Ubiq is an open source platform. It is designed to be easily extensible. It enables development of applications or systems that would be difficult or time-consuming on commercial systems.</description></item><item><title>Ubiq Tutorial at IEEE VR 2025</title><link>https://ucl-vr.github.io/ubiq-website/blog/ubiq-tutorial-at-ieee-vr-2025/</link><pubDate>Wed, 05 Mar 2025 09:19:42 +0100</pubDate><guid>https://ucl-vr.github.io/ubiq-website/blog/ubiq-tutorial-at-ieee-vr-2025/</guid><description>Full sets of slides and video of the tutorial will be available after IEEE VR 2025. Summary In this tutorial we will explore how to build a wide variety of collaborative extended reality (XR) systems using the Ubiq software. Ubiq is an open source platform. It is designed to be easily extensible. It enables development of applications or systems that would be difficult or time-consuming on commercial systems. The tutorial will start with basic concepts, but then explore how more complete demonstrations can be built using new features that have been built on Ubiq in the past couple of years.</description></item><item><title>Meta Avatars in Ubiq</title><link>https://ucl-vr.github.io/ubiq-website/blog/meta-avatars-in-ubiq/</link><pubDate>Thu, 06 Feb 2025 00:00:00 +0000</pubDate><guid>https://ucl-vr.github.io/ubiq-website/blog/meta-avatars-in-ubiq/</guid><description>Most of my PhD work revolves around content creation in VR using record and replay techniques. Record and replay facilitates the animation of virtual characters enormously by letting the user record their own movements and replay them on a virtual character.
In the past, I have often worked with simple avatars (no legs or arms), but for my latest project I wanted to have full-body avatars, ideally with the possibility to add hand and face tracking at a later stage.</description></item><item><title>New Desktop Control Scheme</title><link>https://ucl-vr.github.io/ubiq-website/blog/new-desktop-control-scheme/</link><pubDate>Mon, 19 Aug 2024 09:19:42 +0100</pubDate><guid>https://ucl-vr.github.io/ubiq-website/blog/new-desktop-control-scheme/</guid><description>The motivation for the new controls are to make it easier to build cross-platform applications using the XR Interaction Toolkit. For example, an application targetting WebXR that is meant to be used in both 2D mode and VR mode.
The Desktop Controls replace the XR Device Simulator as the default 2D controls for the samples, so it&amp;rsquo;s no longer necessary to import the XR Device Simulator if you don&amp;rsquo;t want to use it.</description></item><item><title>VR for Clinical Reasoning</title><link>https://ucl-vr.github.io/ubiq-website/blog/vr-for-clinical-reasoning/</link><pubDate>Fri, 19 Apr 2024 12:00:00 +0000</pubDate><guid>https://ucl-vr.github.io/ubiq-website/blog/vr-for-clinical-reasoning/</guid><description>This is a guest post by Endrit Pajaziti. Endrit is a researcher at the Institute of Cardiovascular Science and co-creator of VheaRts. Previously the VheaRts team wrote about their experiences working with Ubiq to demo VheaRts at the WCPCCS conference (link). They&amp;rsquo;ve since extended out their application to aid real-time clinical training. Thanks Endrit for sharing this with us! &amp;ndash; Ben Congdon
Around the globe, a common theme in healthcare is the seemingly ever-increasing workloads which directly affect the time clinical staff have to commit to training and practice.</description></item><item><title>Local Deployments with Docker</title><link>https://ucl-vr.github.io/ubiq-website/blog/local-deployments-with-docker/</link><pubDate>Tue, 20 Feb 2024 00:00:00 +0000</pubDate><guid>https://ucl-vr.github.io/ubiq-website/blog/local-deployments-with-docker/</guid><description>Installing the Ubiq server is straightforward. However, to be able to use all its features requires a few dependencies.
These containers are designed to support local deployments for things such as experiments, or special events.
In the future we aim to add streamlined support for cloud service providers such as AWS as well.
Docker For our containerisation we use Docker, as it is extensive and highly popular, maximising the likelihood of users being able to find support for it in whatever ecosystem they&amp;rsquo;d like to deploy.</description></item><item><title>Single Actor, Multiple Roles</title><link>https://ucl-vr.github.io/ubiq-website/blog/single-actor-multiple-roles/</link><pubDate>Fri, 05 Jan 2024 00:00:00 +0000</pubDate><guid>https://ucl-vr.github.io/ubiq-website/blog/single-actor-multiple-roles/</guid><description>We presented our paper Supporting Co-Presence in Populated Virtual Environments by Actor Takeover of Animated Characters at ISMAR 2023.
The advancement of consumer virtual reality (VR) systems and high-speed internet services has enabled a broad range of new social virtual reality (SVR) applications. To create experiences that appear to be densely populated we can augment users with avatars representing autonomous agent simulations. Such agents might have a similar appearance as user avatars and thus the user might expect them to have at least some reactive and communicative behaviours.</description></item><item><title>Server Scalability at DS-RT 23</title><link>https://ucl-vr.github.io/ubiq-website/blog/server-scalability-at-ds-rt-23/</link><pubDate>Thu, 07 Dec 2023 10:00:00 +0000</pubDate><guid>https://ucl-vr.github.io/ubiq-website/blog/server-scalability-at-ds-rt-23/</guid><description>Ubiq is logically Peer to Peer, but when communicating over the public internet the Ubiq server is used as a hub. Messages from rooms are duplicated or &amp;ldquo;fanned-out&amp;rdquo;. This implementation is simple and robust, but can create a choke-point when large numbers of users congregate in one room: and this is what the paper is focused on.
To see why this is, and understand the paper&amp;rsquo;s goals, we need a wider view of scalability in social VR&amp;hellip;</description></item><item><title>Ubiq Server Upgrades and New Features</title><link>https://ucl-vr.github.io/ubiq-website/blog/ubiq-server-upgrades-and-new-features/</link><pubDate>Fri, 24 Nov 2023 09:19:42 +0100</pubDate><guid>https://ucl-vr.github.io/ubiq-website/blog/ubiq-server-upgrades-and-new-features/</guid><description>We have just released a major update to our Node platform code. This encompasses the server, and JavaScript modules for use in the Browser.
This update includes an upgrade to TypeScript, new unit tests, a new status module and a number of other quality of life improvements.
The server API remains unchanged, so this upgrade has already been applied in-place and transparently. If you do not write code for the server, you will not need to do anything.</description></item><item><title>Content Creation Using Record and Replay</title><link>https://ucl-vr.github.io/ubiq-website/blog/content-creation-using-record-and-replay/</link><pubDate>Fri, 17 Nov 2023 00:00:00 +0000</pubDate><guid>https://ucl-vr.github.io/ubiq-website/blog/content-creation-using-record-and-replay/</guid><description>We presented our paper Dialogues For One: Single-User Content Creation Using Immersive Record and Replay at VRST 2023.
With the help of indicators showing when a recorded avatar would speak or grab an object, a single user could create believable conversations and object interactions with their previously recorded self. Watch the video to see how we created single-user dialogues and object interaction! In the past, we implemented a record and replay tool in Ubiq with which we could easily populate a virtual space with many characters by recording over previous replays.</description></item></channel></rss>