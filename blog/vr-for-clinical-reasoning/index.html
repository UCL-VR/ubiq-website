<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="ie=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><link rel=preload as=font href=https://ubiq.online/fonts/vendor/nunito-sans/nunito-sans-v11-latin-regular.woff2 type=font/woff2 crossorigin><link rel=preload as=font href=https://ubiq.online/fonts/vendor/nunito/nunito-v22-latin-700.woff2 type=font/woff2 crossorigin><script integrity="sha512-RBYr6Ld4w1yVqaACrgrBLQfPgGhj/1jyacA74WxJ1KM6KVcSWymwrdDwb3HDcdpwiNJ5yssot1He0U9vXoQVlg==">(()=>{var b=window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches,a=localStorage.getItem("theme");b&&a===null&&(localStorage.setItem("theme","dark"),document.documentElement.setAttribute("data-dark-mode","")),b&&a==="dark"&&document.documentElement.setAttribute("data-dark-mode",""),a==="dark"&&document.documentElement.setAttribute("data-dark-mode","")})()</script><link rel=stylesheet href=/main.be2ac79d46942b3c1be9b102cb3f8714a31099e650d6d5c9d08f182ec3ddb8f751c2564f2274fddc98ae819330a1da887d17d15f3991255d9d7bf58ae0f3ed4f.css integrity="sha512-virHnUaUKzwb6bECyz+HFKMQmeZQ1tXJ0I8YLsPduPdRwlZPInT93JiugZMwodqIfRfRXzmRJV2de/WK4PPtTw==" crossorigin=anonymous><noscript><style>img.lazyload{display:none}</style></noscript><meta name=robots content="index, follow"><meta name=googlebot content="index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1"><meta name=bingbot content="index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1"><title>VR for Clinical Reasoning Ubiq</title><meta name=description content="A post describing using Ubiq and VheaRts for Virtual Reality clinical training"><link rel=canonical href=https://ubiq.online/blog/vr-for-clinical-reasoning/><meta property="og:locale" content="en_US"><meta property="og:type" content="article"><meta property="og:title" content="VR for Clinical Reasoning"><meta property="og:description" content="A post describing using Ubiq and VheaRts for Virtual Reality clinical training"><meta property="og:url" content="https://ubiq.online/blog/vr-for-clinical-reasoning/"><meta property="og:site_name" content="Ubiq"><meta property="article:published_time" content="2024-04-19T12:00:00+00:00"><meta property="article:modified_time" content="2024-06-04T18:21:12+01:00"><meta property="og:image:width" content="1280"><meta property="og:image:height" content="640"><meta property="og:image:alt" content="VR for Clinical Reasoning"><meta property="og:image" content="https://ubiq.online/images/banner.png"><meta property="og:image:width" content="1280"><meta property="og:image:height" content="640"><meta property="og:image:alt" content="Ubiq"><meta name=twitter:card content="summary_large_image"><meta name=twitter:site content><meta name=twitter:creator content><meta name=twitter:title content="VR for Clinical Reasoning"><meta name=twitter:description content="A post describing using Ubiq and VheaRts for Virtual Reality clinical training"><meta name=twitter:image content><meta name=twitter:image:alt content="VR for Clinical Reasoning"><script type=application/ld+json>{"@context":"https://schema.org","@graph":[{"@type":"Organization","@id":"https://ubiq.online/#/schema/organization/1","name":"Ubiq","url":"https://ubiq.online/","sameAs":["https://github.com/UCL-VR/ubiq"],"logo":{"@type":"ImageObject","@id":"https://ubiq.online/#/schema/image/1","url":"https://ubiq.online/images/logos/ubiq-logo.png","width":512,"height":512,"caption":"Ubiq"},"image":{"@id":"https://ubiq.online/#/schema/image/1"}},{"@type":"WebSite","@id":"https://ubiq.online/#/schema/website/1","url":"https://ubiq.online/","name":"Ubiq","description":"A Unity networking library for research, teaching and development, maintained by the Virtual Environments and Computer Graphics group at UCL. Ubiq is 100% free and open source.","publisher":{"@id":"https://ubiq.online/#/schema/organization/1"}},{"@type":"WebPage","@id":"https://ubiq.online/blog/vr-for-clinical-reasoning/","url":"https://ubiq.online/blog/vr-for-clinical-reasoning/","name":"VR for Clinical Reasoning","description":"A post describing using Ubiq and VheaRts for Virtual Reality clinical training","isPartOf":{"@id":"https://ubiq.online/#/schema/website/1"},"about":{"@id":"https://ubiq.online/#/schema/organization/1"},"datePublished":"2024-04-19T12:00:00CET","dateModified":"2024-06-04T18:21:12CET","breadcrumb":{"@id":"https://ubiq.online/blog/vr-for-clinical-reasoning/#/schema/breadcrumb/1"},"primaryImageOfPage":{"@id":"https://ubiq.online/blog/vr-for-clinical-reasoning/#/schema/image/2"},"inLanguage":"en-US","potentialAction":[{"@type":"ReadAction","target":["https://ubiq.online/blog/vr-for-clinical-reasoning/"]}]},{"@type":"BreadcrumbList","@id":"https://ubiq.online/blog/vr-for-clinical-reasoning/#/schema/breadcrumb/1","name":"Breadcrumbs","itemListElement":[{"@type":"ListItem","position":1,"item":{"@type":"WebPage","@id":"https://ubiq.online/","url":"https://ubiq.online/","name":"Home"}},{"@type":"ListItem","position":2,"item":{"@type":"WebPage","@id":"https://ubiq.online/blog/","url":"https://ubiq.online/blog/","name":"Blog"}},{"@type":"ListItem","position":3,"item":{"@id":"https://ubiq.online/blog/vr-for-clinical-reasoning/"}}]},{"@context":"https://schema.org","@graph":[{"@type":"Article","@id":"https://ubiq.online/#/schema/article/1","headline":"VR for Clinical Reasoning","description":"A post describing using Ubiq and VheaRts for Virtual Reality clinical training","isPartOf":{"@id":"https://ubiq.online/blog/vr-for-clinical-reasoning/"},"mainEntityOfPage":{"@id":"https://ubiq.online/blog/vr-for-clinical-reasoning/"},"datePublished":"2024-04-19T12:00:00CET","dateModified":"2024-06-04T18:21:12CET","author":{"@id":"https://ubiq.online/#/schema/person/2"},"publisher":{"@id":"https://ubiq.online/#/schema/organization/1"},"image":{"@id":"https://ubiq.online/blog/vr-for-clinical-reasoning/#/schema/image/2"}}]},{"@context":"https://schema.org","@graph":[{"@type":"Person","@id":"https://ubiq.online/#/schema/person/2","name":"Nels Numan","sameAs":[]}]},{"@context":"https://schema.org","@graph":[{"@type":"ImageObject","@id":"https://ubiq.online/blog/vr-for-clinical-reasoning/#/schema/image/2","url":null,"contentUrl":null,"width":1826,"height":874,"caption":"VR for Clinical Reasoning"}]}]}</script><meta name=theme-color content="#fff"><link rel=apple-touch-icon sizes=180x180 href=https://ubiq.online/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=https://ubiq.online/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=https://ubiq.online/favicon-16x16.png><link rel=manifest href=https://ubiq.online/site.webmanifest></head><body class="single section blog"><div class=header-bar></div><header class="navbar navbar-expand-md navbar-light doks-navbar"><nav class="container-xxl flex-wrap flex-md-nowrap" aria-label="Main navigation"><a class="navbar-brand p-0 me-auto" href=/ aria-label=Bootstrap>Ubiq</a>
<button class="btn btn-menu d-block d-md-none order-5" type=button data-bs-toggle=offcanvas data-bs-target=#offcanvasDoks aria-controls=offcanvasDoks aria-label="Open main menu"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"><line x1="3" y1="12" x2="21" y2="12"/><line x1="3" y1="6" x2="21" y2="6"/><line x1="3" y1="18" x2="21" y2="18"/></svg></button><div class="offcanvas offcanvas-start border-0 py-md-1" tabindex=-1 id=offcanvasDoks data-bs-backdrop=true aria-labelledby=offcanvasDoksLabel><div class="header-bar d-md-none"></div><div class="offcanvas-header d-md-none"><h2 class="h5 offcanvas-title ps-2" id=offcanvasDoksLabel><a class=text-dark href=/>Ubiq</a></h2><button type=button class="btn-close text-reset me-2" data-bs-dismiss=offcanvas aria-label="Close main menu"></button></div><div class="offcanvas-body px-4"><h3 class="h6 text-uppercase mb-3 d-md-none">Main</h3><ul class="nav flex-column flex-md-row ms-md-n3"><li class=nav-item><a class="nav-link ps-0 py-1" href=https://ucl-vr.github.io/ubiq/>Docs</a></li><li class=nav-item><a class="nav-link ps-0 py-1" href=/showcase/>Showcase</a></li><li class=nav-item><a class="nav-link ps-0 py-1 active" href=/blog/>Blog</a></li><li class=nav-item><a class="nav-link ps-0 py-1" href=/publication/>Publications</a></li><li class=nav-item><a class="nav-link ps-0 py-1" href=/teaching>Teaching</a></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle ps-0 py-1" href=# id=navbarDropdownMenuLink role=button data-bs-toggle=dropdown aria-expanded=false>Contact
<span class=dropdown-caret><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-down"><polyline points="6 9 12 15 18 9"/></svg></span></a><ul class="dropdown-menu dropdown-menu-main shadow rounded border-0" aria-labelledby=navbarDropdownMenuLink><li><a class=dropdown-item href=https://github.com/UCL-VR/ubiq/discussions/categories/q-a>â†— Ask a Question</a></li><li><a class=dropdown-item href=/contributors/>Contributors</a></li><li><a class=dropdown-item href=/media/>Media</a></li></ul></li></ul><hr class="text-black-50 my-4 d-md-none"><h3 class="h6 text-uppercase mb-3 d-md-none">Socials</h3><ul class="nav flex-column flex-md-row ms-md-auto me-md-n5 pe-md-2"><li class=nav-item><a class="nav-link ps-0 py-1" href=https://discord.gg/cZYzdcxAAB><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 128 128" fill="#000" stroke="currentcolor" stroke-width="5" stroke-linecap="round" stroke-linejoin="round" class="feather feather-discord"><path d="M45.23 57.2c-6.16.0-11.17 5.6-11.17 12.48s5 12.47 11.17 12.47 11.16-5.59 11.16-12.47S51.38 57.2 45.23 57.2zm0 21c-4 0-7.17-3.8-7.17-8.47s3.21-8.48 7.17-8.48 7.16 3.8 7.16 8.48-3.21 8.42-7.16 8.42z"/><path d="M121.83 59.58a156.78 156.78.0 00-11.52-31 2.1 2.1.0 00-.71-.77 87.08 87.08.0 00-15.23-7.17C84.55 17.07 79.91 17 79.72 17a2 2 0 00-2 1.72l-.6 4.17a133.14 133.14.0 00-26.28.0l-.6-4.17a2 2 0 00-2-1.72c-.19.0-4.83.0-14.65 3.61A87.08 87.08.0 0018.4 27.81a2.1 2.1.0 00-.71.77 156.72 156.72.0 00-11.52 31C1 80.46.0 90.91.0 91.34a2 2 0 00.49 1.5 55.2 55.2.0 0018.2 12.74A76.32 76.32.0 0038.48 111a2 2 0 001.92-1l5.4-9.25A105.08 105.08.0 0064 102.24a105.08 105.08.0 0018.2-1.51L87.6 110a2 2 0 001.72 1h.2a76.32 76.32.0 0019.78-5.38 55.2 55.2.0 0018.2-12.74 2 2 0 00.49-1.5C128 90.91 127.05 80.46 121.83 59.58zm-14.06 42.31a76.76 76.76.0 01-17.39 4.92l-4.08-7c4.68-1.24 14.42-4.46 21.83-11.2a2 2 0 10-2.69-3c-9 8.23-22.46 10.84-22.6 10.87h-.06A96.59 96.59.0 0164 98.24a96.59 96.59.0 01-18.78-1.7h-.06c-.14.0-13.55-2.64-22.6-10.87a2 2 0 10-2.69 3c7.41 6.74 17.15 10 21.83 11.2l-4.08 7a76.08 76.08.0 01-17.39-4.92A52.24 52.24.0 014.08 90.8c.33-2.91 1.68-13.07 6-30.24A156.25 156.25.0 0121 30.92 88.17 88.17.0 0135 24.4a61.35 61.35.0 0111.58-3.19l.35 2.39c-4 1-13.85 3.86-21.65 9.53a2 2 0 102.36 3.23c8.82-6.41 21-9.06 21.86-9.25A118.4 118.4.0 0164 26.27a117.64 117.64.0 0114.51.84c.91.19 13 2.83 21.86 9.25a2 2 0 102.36-3.23c-7.8-5.67-17.61-8.52-21.65-9.53l.35-2.39A61.75 61.75.0 0193 24.4a88.17 88.17.0 0114 6.52 156.25 156.25.0 0111 29.64c4.29 17.17 5.64 27.33 6 30.24a52.24 52.24.0 01-16.23 11.09z"/><path d="M82.77 57.2c-6.15.0-11.16 5.6-11.16 12.48s5 12.47 11.16 12.47 11.17-5.59 11.17-12.47S88.93 57.2 82.77 57.2zm0 21c-4 0-7.16-3.8-7.16-8.47s3.21-8.48 7.16-8.48 7.17 3.8 7.17 8.48S86.73 78.15 82.77 78.15z"/></svg><small class="ms-2 d-md-none">Discord</small></a></li><li class=nav-item><a class="nav-link ps-0 py-1" href=https://github.com/UCL-VR/ubiq/><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-github"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg><small class="ms-2 d-md-none">GitHub</small></a></li></ul></div></div><button id=mode class="btn btn-link order-md-1" type=button aria-label="Toggle user interface mode">
<span class=toggle-dark><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-moon"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg></span><span class=toggle-light><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-sun"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></span></button></nav></header><div class="wrap container-xxl" role=document><div class=content><div class="row justify-content-center"><div class="col-md-12 col-lg-10 col-xl-8"><article><div class=blog-header><h1>VR for Clinical Reasoning</h1><p><small>Posted April 19, 2024 by <a class="stretched-link position-relative" href=/contributors/endrit-pajaziti/>Endrit Pajaziti</a>&nbsp;&dash;&nbsp;<strong>4&nbsp;min read</strong></small><p></div><p class=lead>An update from the Institute of Cardiovascular Science on extending their VheaRts application to support clinical scenario simulation for training, with Ubiq as the cross-platform multi-user backend.</p><p><em>This is a guest post by Endrit Pajaziti. Endrit is a researcher at the Institute of Cardiovascular Science and co-creator of <a href=https://www.vhearts.org/>VheaRts</a>. Previously the VheaRts team wrote about their experiences working with Ubiq to demo VheaRts at the WCPCCS conference (<a href=/blog/using-ubiq-to-enable-independent-setups/>link</a>). They&rsquo;ve since extended out their application to aid real-time clinical training. Thanks Endrit for sharing this with us! &ndash; Ben Congdon</em></p><p>Around the globe, a common theme in healthcare is the seemingly ever-increasing workloads which directly affect the time clinical staff have to commit to training and practice. At Great Ormond Street Hospital, the Centre for Clinical Simulation has been working hard to bridge the gap and provide the necessary means for staff to practice essential skills - varying from communication-based training (using actors) to emergency paediatric scenario simulation (with high-end manikins). At the centre, there are dedicated, fully equipped wards where participants can take part in mock clinical scenarios while monitored through a one-way glass window. The team can adjust certain parameters in real-time, such as the state of the manikin (for example, making the pupils dilate or simulating a seizure) or to the vitals monitor in the mock ward. This works extremely well, however the growing potential of VR presents a few questions, such as: can we do this remotely? Can we do this with multiple participants at the same time? Our manikins often have issues, can we do clinical simulation more cheaply using VR headsets?</p><p>There are numerous difficulties involved in building a VR application which can replicate the functionality of one of the simulation rooms in the hospital. Many of these lie in the difficulty to build realistic, believable and intuitive graphics and interactions within a clinical environment. Our plan was to use parts of our VheaRts application demonstrated at the World Congress of Pediatric Cardiology and Surgery, previously written about on this site (<a href=/blog/using-ubiq-to-enable-independent-setups/>link</a>). Therefore, considering all these factors, we decided to start by building a low-fidelity application, and testing the core functionalities of a VR clinical simulation environment with users to see if a prototype could be useful. This approach was chosen since it would reduce the time to the first prototype and allow us to see if we could effectively use VR to run scenarios with students and trainees. Also, even with a lot of effort, a &ldquo;realistic&rdquo; approach may still be insufficiently convincing, thus creating a barrier for the participants to authentically interact with the content and learn from each other and the scenario.</p><p><figure class=figure><img class="figure-img img-fluid lazyload blur-up" data-sizes=auto src=https://ubiq.online/blog/vr-for-clinical-reasoning/conference_hu3e07b12657e4d5f657acad4f0d6eb280_2810201_20x0_resize_q75_box.jpg data-srcset="https://ubiq.online/blog/vr-for-clinical-reasoning/conference_hu3e07b12657e4d5f657acad4f0d6eb280_2810201_900x0_resize_q75_box.jpg 900w,https://ubiq.online/blog/vr-for-clinical-reasoning/conference_hu3e07b12657e4d5f657acad4f0d6eb280_2810201_800x0_resize_q75_box.jpg 800w,https://ubiq.online/blog/vr-for-clinical-reasoning/conference_hu3e07b12657e4d5f657acad4f0d6eb280_2810201_700x0_resize_q75_box.jpg 700w,https://ubiq.online/blog/vr-for-clinical-reasoning/conference_hu3e07b12657e4d5f657acad4f0d6eb280_2810201_600x0_resize_q75_box.jpg 600w,https://ubiq.online/blog/vr-for-clinical-reasoning/conference_hu3e07b12657e4d5f657acad4f0d6eb280_2810201_500x0_resize_q75_box.jpg 500w" width=4000 height=3000 alt="Dr Andrew Cook demonstrating a heart procedure at the World Congress of Pediatric Cardiology and Surgery (WCPCCS) using VheaRts and Ubiq"><noscript><img class="figure-img img-fluid" sizes=100vw srcset="https://ubiq.online/blog/vr-for-clinical-reasoning/conference_hu3e07b12657e4d5f657acad4f0d6eb280_2810201_900x0_resize_q75_box.jpg 900w,https://ubiq.online/blog/vr-for-clinical-reasoning/conference_hu3e07b12657e4d5f657acad4f0d6eb280_2810201_800x0_resize_q75_box.jpg 800w,https://ubiq.online/blog/vr-for-clinical-reasoning/conference_hu3e07b12657e4d5f657acad4f0d6eb280_2810201_700x0_resize_q75_box.jpg 700w,https://ubiq.online/blog/vr-for-clinical-reasoning/conference_hu3e07b12657e4d5f657acad4f0d6eb280_2810201_600x0_resize_q75_box.jpg 600w,https://ubiq.online/blog/vr-for-clinical-reasoning/conference_hu3e07b12657e4d5f657acad4f0d6eb280_2810201_500x0_resize_q75_box.jpg 500w" src=https://ubiq.online/blog/vr-for-clinical-reasoning/conference.jpg width=4000 height=3000 alt="Dr Andrew Cook demonstrating a heart procedure at the World Congress of Pediatric Cardiology and Surgery (WCPCCS) using VheaRts and Ubiq"></noscript></figure>Dr Andrew Cook demonstrating a heart procedure at the World Congress of Pediatric Cardiology and Surgery (WCPCCS) using VheaRts and Ubiq.</p><p>For these reasons, we decided to create a low-fidelity environment in which participants could practice communication, team-working and following clinical protocols to work through and solve scenarios. The term we used for this was &ldquo;clinical reasoning&rdquo;. We chose to use Ubiq since it provided all of the functionalities we required, such as being able to create an instance of a room in a secure server (based within UCL), generate avatars for users, send messages over the network and store the states of variables as &ldquo;room properties&rdquo;. As also shown in WCPCCS 2023, the ability to use a local instance of Ubiq on a laptop/router combination gives us the possibility to take the setup anywhere, which is especially useful in healthcare since hospital Wi-Fi is notoriously unreliable and firewalls are often an issue when using networked applications.</p><p>The way the application works is that there are two versions: a Quest (android) build and a windows build. While the users are immersed in the VR room, the educator has control over the environment using the desktop build. Parameters such as vitals, manikin states, devices and more can be tweaked in real-time. A text log is present in both VR/PC which allows the communicator to note specific events (which might not have a dedicated button), and these can be seen by participants in VR. This could be noting down the dosage of a drug administered (for example). A panel for entering bloods values (creating a bloods report) is a secondary use of the text log. In VR, users have the ability to read the text log, to read clinical protocols which have been transformed into VR-suitable versions and also to enter/edit their avatar name. They can also inspect the states of the manikin, which are presented as lists hovering above the manikin model. The manikin states are organised in a ABCDE assessment format, to encourage the users to follow clinical protocols in emergency situations (airways, breathing, circulation, disability, exposure). Some pre-built scenario templates have been included in the application, such as a sepsis and seizure scenario, which also have the appropriate clinical protocols built in VR.</p><p>The application is currently in a prototype phase and is ready for testing within the next few weeks, and we will be recruiting medical students from UCL for a first run through.</p><p><figure class=figure><img class="figure-img img-fluid lazyload blur-up" data-sizes=auto src=https://ubiq.online/blog/vr-for-clinical-reasoning/educator-view-1_hub252448fd342c251583a534c4930f523_765684_20x0_resize_box_3.png data-srcset="https://ubiq.online/blog/vr-for-clinical-reasoning/educator-view-1_hub252448fd342c251583a534c4930f523_765684_900x0_resize_box_3.png 900w,https://ubiq.online/blog/vr-for-clinical-reasoning/educator-view-1_hub252448fd342c251583a534c4930f523_765684_800x0_resize_box_3.png 800w,https://ubiq.online/blog/vr-for-clinical-reasoning/educator-view-1_hub252448fd342c251583a534c4930f523_765684_700x0_resize_box_3.png 700w,https://ubiq.online/blog/vr-for-clinical-reasoning/educator-view-1_hub252448fd342c251583a534c4930f523_765684_600x0_resize_box_3.png 600w,https://ubiq.online/blog/vr-for-clinical-reasoning/educator-view-1_hub252448fd342c251583a534c4930f523_765684_500x0_resize_box_3.png 500w" width=1680 height=945 alt="Educator (Desktop) view - blood panel"><noscript><img class="figure-img img-fluid" sizes=100vw srcset="https://ubiq.online/blog/vr-for-clinical-reasoning/educator-view-1_hub252448fd342c251583a534c4930f523_765684_900x0_resize_box_3.png 900w,https://ubiq.online/blog/vr-for-clinical-reasoning/educator-view-1_hub252448fd342c251583a534c4930f523_765684_800x0_resize_box_3.png 800w,https://ubiq.online/blog/vr-for-clinical-reasoning/educator-view-1_hub252448fd342c251583a534c4930f523_765684_700x0_resize_box_3.png 700w,https://ubiq.online/blog/vr-for-clinical-reasoning/educator-view-1_hub252448fd342c251583a534c4930f523_765684_600x0_resize_box_3.png 600w,https://ubiq.online/blog/vr-for-clinical-reasoning/educator-view-1_hub252448fd342c251583a534c4930f523_765684_500x0_resize_box_3.png 500w" src=https://ubiq.online/blog/vr-for-clinical-reasoning/educator-view-1.png width=1680 height=945 alt="Educator (Desktop) view - blood panel"></noscript></figure>Educator (Desktop) view - blood panel.</p><p><figure class=figure><img class="figure-img img-fluid lazyload blur-up" data-sizes=auto src=https://ubiq.online/blog/vr-for-clinical-reasoning/educator-view-2_hu45b4da7e0715a40800c4724424b7298b_823925_20x0_resize_box_3.png data-srcset="https://ubiq.online/blog/vr-for-clinical-reasoning/educator-view-2_hu45b4da7e0715a40800c4724424b7298b_823925_900x0_resize_box_3.png 900w,https://ubiq.online/blog/vr-for-clinical-reasoning/educator-view-2_hu45b4da7e0715a40800c4724424b7298b_823925_800x0_resize_box_3.png 800w,https://ubiq.online/blog/vr-for-clinical-reasoning/educator-view-2_hu45b4da7e0715a40800c4724424b7298b_823925_700x0_resize_box_3.png 700w,https://ubiq.online/blog/vr-for-clinical-reasoning/educator-view-2_hu45b4da7e0715a40800c4724424b7298b_823925_600x0_resize_box_3.png 600w,https://ubiq.online/blog/vr-for-clinical-reasoning/educator-view-2_hu45b4da7e0715a40800c4724424b7298b_823925_500x0_resize_box_3.png 500w" width=1680 height=945 alt="Educator (Desktop) view - manikin panel"><noscript><img class="figure-img img-fluid" sizes=100vw srcset="https://ubiq.online/blog/vr-for-clinical-reasoning/educator-view-2_hu45b4da7e0715a40800c4724424b7298b_823925_900x0_resize_box_3.png 900w,https://ubiq.online/blog/vr-for-clinical-reasoning/educator-view-2_hu45b4da7e0715a40800c4724424b7298b_823925_800x0_resize_box_3.png 800w,https://ubiq.online/blog/vr-for-clinical-reasoning/educator-view-2_hu45b4da7e0715a40800c4724424b7298b_823925_700x0_resize_box_3.png 700w,https://ubiq.online/blog/vr-for-clinical-reasoning/educator-view-2_hu45b4da7e0715a40800c4724424b7298b_823925_600x0_resize_box_3.png 600w,https://ubiq.online/blog/vr-for-clinical-reasoning/educator-view-2_hu45b4da7e0715a40800c4724424b7298b_823925_500x0_resize_box_3.png 500w" src=https://ubiq.online/blog/vr-for-clinical-reasoning/educator-view-2.png width=1680 height=945 alt="Educator (Desktop) view - manikin panel"></noscript></figure>Educator (Desktop) view - manikin panel.</p><p><figure class=figure><img class="figure-img img-fluid lazyload blur-up" data-sizes=auto src=https://ubiq.online/blog/vr-for-clinical-reasoning/vr-view_hud04cb6f8d3ef011730229d1740bf2cfb_892337_20x0_resize_box_3.png data-srcset="https://ubiq.online/blog/vr-for-clinical-reasoning/vr-view_hud04cb6f8d3ef011730229d1740bf2cfb_892337_900x0_resize_box_3.png 900w,https://ubiq.online/blog/vr-for-clinical-reasoning/vr-view_hud04cb6f8d3ef011730229d1740bf2cfb_892337_800x0_resize_box_3.png 800w,https://ubiq.online/blog/vr-for-clinical-reasoning/vr-view_hud04cb6f8d3ef011730229d1740bf2cfb_892337_700x0_resize_box_3.png 700w,https://ubiq.online/blog/vr-for-clinical-reasoning/vr-view_hud04cb6f8d3ef011730229d1740bf2cfb_892337_600x0_resize_box_3.png 600w,https://ubiq.online/blog/vr-for-clinical-reasoning/vr-view_hud04cb6f8d3ef011730229d1740bf2cfb_892337_500x0_resize_box_3.png 500w" width=978 height=978 alt="Student (VR) view"><noscript><img class="figure-img img-fluid" sizes=100vw srcset="https://ubiq.online/blog/vr-for-clinical-reasoning/vr-view_hud04cb6f8d3ef011730229d1740bf2cfb_892337_900x0_resize_box_3.png 900w,https://ubiq.online/blog/vr-for-clinical-reasoning/vr-view_hud04cb6f8d3ef011730229d1740bf2cfb_892337_800x0_resize_box_3.png 800w,https://ubiq.online/blog/vr-for-clinical-reasoning/vr-view_hud04cb6f8d3ef011730229d1740bf2cfb_892337_700x0_resize_box_3.png 700w,https://ubiq.online/blog/vr-for-clinical-reasoning/vr-view_hud04cb6f8d3ef011730229d1740bf2cfb_892337_600x0_resize_box_3.png 600w,https://ubiq.online/blog/vr-for-clinical-reasoning/vr-view_hud04cb6f8d3ef011730229d1740bf2cfb_892337_500x0_resize_box_3.png 500w" src=https://ubiq.online/blog/vr-for-clinical-reasoning/vr-view.png width=978 height=978 alt="Student (VR) view"></noscript></figure>Student (VR) view.</p></article></div></div></div></div><section class="section section-sm mt-n5 mb-3"><div class=container><div class="row justify-content-center"><div class="col-md-12 col-lg-10 col-xl-8"></div></div></div></section><footer class="footer text-muted"><div class=container-xxl><div class=row><div class="col-lg-8 order-last order-lg-first"><ul class=list-inline><li class=list-inline-item></li></ul></div><div class="col-lg-8 order-first order-lg-last text-lg-end"><ul class=list-inline><li class=list-inline-item><a href=/privacy-policy/>Privacy</a></li></ul></div></div></div></footer><script data-goatcounter=https://ubiq.goatcounter.com/count async src=//gc.zgo.at/count.js></script>
<script src=/js/bootstrap.min.fdbe9b9ba88a036135318f3c721784d684ac9e3280fe282cc80d7d49f7f9c82780cd54228c1608685a230c09984300d7946fc471734d566fcebc148b65bd16db.js integrity="sha512-/b6bm6iKA2E1MY88cheE1oSsnjKA/igsyA19Sff5yCeAzVQijBYIaFojDAmYQwDXlG/EcXNNVm/OvBSLZb0W2w==" crossorigin=anonymous defer></script>
<script src=/js/highlight.min.2a3ca603c4e5468838fb437bc036b9ddc036b6668b5dd45804f048229ea684f98f5928dd485b41db90e55aaa28b36600341f082d2726650a0a394250b6bf3ac1.js integrity="sha512-KjymA8TlRog4+0N7wDa53cA2tmaLXdRYBPBIIp6mhPmPWSjdSFtB25DlWqoos2YANB8ILScmZQoKOUJQtr86wQ==" crossorigin=anonymous defer></script>
<script src=/main.min.7692813ef22de5d343339990192d5774c0742a9334f8f57bb78245f5ab0e02861e3e47e7308e649ca0173ef9e307477de2769299fdb90a9e4a5e327df94553b7.js integrity="sha512-dpKBPvIt5dNDM5mQGS1XdMB0KpM0+PV7t4JF9asOAoYePkfnMI5knKAXPvnjB0d94naSmf25Cp5KXjJ9+UVTtw==" crossorigin=anonymous defer></script></body></html>