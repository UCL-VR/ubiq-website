<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="ie=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><link rel=preload as=font href=https://ubiq.online/fonts/vendor/nunito-sans/nunito-sans-v11-latin-regular.woff2 type=font/woff2 crossorigin><link rel=preload as=font href=https://ubiq.online/fonts/vendor/nunito/nunito-v22-latin-700.woff2 type=font/woff2 crossorigin><script integrity="sha512-RBYr6Ld4w1yVqaACrgrBLQfPgGhj/1jyacA74WxJ1KM6KVcSWymwrdDwb3HDcdpwiNJ5yssot1He0U9vXoQVlg==">(()=>{var b=window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches,a=localStorage.getItem("theme");b&&a===null&&(localStorage.setItem("theme","dark"),document.documentElement.setAttribute("data-dark-mode","")),b&&a==="dark"&&document.documentElement.setAttribute("data-dark-mode",""),a==="dark"&&document.documentElement.setAttribute("data-dark-mode","")})()</script><link rel=stylesheet href=/main.d34019d0fddba852cf3de0b54c66c4f2cc02f70a0b095f0095ed7df1d0c7c432f36e76345ea0c409345d8cc8df9a12a309551916333016d0a96d575e9f816da0.css integrity="sha512-00AZ0P3bqFLPPeC1TGbE8swC9woLCV8Ale198dDHxDLzbnY0XqDECTRdjMjfmhKjCVUZFjMwFtCpbVden4FtoA==" crossorigin=anonymous><noscript><style>img.lazyload{display:none}</style></noscript><meta name=robots content="index, follow"><meta name=googlebot content="index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1"><meta name=bingbot content="index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1"><title>Ubiq and Ubiq-Genie Tutorial at IEEE VR 2026 Ubiq</title><meta name=description content="Schedule and instructions for the Ubiq and Ubig-Genie tutorial at IEEE VR 2026."><link rel=canonical href=https://ubiq.online/blog/ubiq-and-ubiq-genie-tutorial-at-ieee-vr-2026/><meta property="og:locale" content="en_US"><meta property="og:type" content="article"><meta property="og:title" content="Ubiq and Ubiq-Genie Tutorial at IEEE VR 2026"><meta property="og:description" content="Schedule and instructions for the Ubiq and Ubig-Genie tutorial at IEEE VR 2026."><meta property="og:url" content="https://ubiq.online/blog/ubiq-and-ubiq-genie-tutorial-at-ieee-vr-2026/"><meta property="og:site_name" content="Ubiq"><meta property="article:published_time" content="2026-01-05T09:19:42+01:00"><meta property="article:modified_time" content="2026-02-04T19:40:18+00:00"><meta property="og:image:width" content="1280"><meta property="og:image:height" content="640"><meta property="og:image:alt" content="Ubiq and Ubiq-Genie Tutorial at IEEE VR 2026"><meta property="og:image" content="https://ubiq.online/images/banner.png"><meta property="og:image:width" content="1280"><meta property="og:image:height" content="640"><meta property="og:image:alt" content="Ubiq"><meta name=twitter:card content="summary_large_image"><meta name=twitter:site content><meta name=twitter:creator content><meta name=twitter:title content="Ubiq and Ubiq-Genie Tutorial at IEEE VR 2026"><meta name=twitter:description content="Schedule and instructions for the Ubiq and Ubig-Genie tutorial at IEEE VR 2026."><meta name=twitter:image content><meta name=twitter:image:alt content="Ubiq and Ubiq-Genie Tutorial at IEEE VR 2026"><script type=application/ld+json>{"@context":"https://schema.org","@graph":[{"@type":"Organization","@id":"https://ubiq.online/#/schema/organization/1","name":"Ubiq","url":"https://ubiq.online/","sameAs":["https://github.com/UCL-VR/ubiq"],"logo":{"@type":"ImageObject","@id":"https://ubiq.online/#/schema/image/1","url":"https://ubiq.online/images/logos/ubiq-logo.png","width":512,"height":512,"caption":"Ubiq"},"image":{"@id":"https://ubiq.online/#/schema/image/1"}},{"@type":"WebSite","@id":"https://ubiq.online/#/schema/website/1","url":"https://ubiq.online/","name":"Ubiq","description":"A Unity networking library for research, teaching and development, maintained by the Virtual Environments and Computer Graphics group at UCL. Ubiq is 100% free and open source.","publisher":{"@id":"https://ubiq.online/#/schema/organization/1"}},{"@type":"WebPage","@id":"https://ubiq.online/blog/ubiq-and-ubiq-genie-tutorial-at-ieee-vr-2026/","url":"https://ubiq.online/blog/ubiq-and-ubiq-genie-tutorial-at-ieee-vr-2026/","name":"Ubiq and Ubiq-Genie Tutorial at IEEE VR 2026","description":"Schedule and instructions for the Ubiq and Ubig-Genie tutorial at IEEE VR 2026.","isPartOf":{"@id":"https://ubiq.online/#/schema/website/1"},"about":{"@id":"https://ubiq.online/#/schema/organization/1"},"datePublished":"2026-01-05T09:19:42CET","dateModified":"2026-02-04T19:40:18CET","breadcrumb":{"@id":"https://ubiq.online/blog/ubiq-and-ubiq-genie-tutorial-at-ieee-vr-2026/#/schema/breadcrumb/1"},"primaryImageOfPage":{"@id":"https://ubiq.online/blog/ubiq-and-ubiq-genie-tutorial-at-ieee-vr-2026/#/schema/image/2"},"inLanguage":"en-US","potentialAction":[{"@type":"ReadAction","target":["https://ubiq.online/blog/ubiq-and-ubiq-genie-tutorial-at-ieee-vr-2026/"]}]},{"@type":"BreadcrumbList","@id":"https://ubiq.online/blog/ubiq-and-ubiq-genie-tutorial-at-ieee-vr-2026/#/schema/breadcrumb/1","name":"Breadcrumbs","itemListElement":[{"@type":"ListItem","position":1,"item":{"@type":"WebPage","@id":"https://ubiq.online/","url":"https://ubiq.online/","name":"Home"}},{"@type":"ListItem","position":2,"item":{"@type":"WebPage","@id":"https://ubiq.online/blog/","url":"https://ubiq.online/blog/","name":"Blog"}},{"@type":"ListItem","position":3,"item":{"@id":"https://ubiq.online/blog/ubiq-and-ubiq-genie-tutorial-at-ieee-vr-2026/"}}]},{"@context":"https://schema.org","@graph":[{"@type":"Article","@id":"https://ubiq.online/#/schema/article/1","headline":"Ubiq and Ubiq-Genie Tutorial at IEEE VR 2026","description":"Schedule and instructions for the Ubiq and Ubig-Genie tutorial at IEEE VR 2026.","isPartOf":{"@id":"https://ubiq.online/blog/ubiq-and-ubiq-genie-tutorial-at-ieee-vr-2026/"},"mainEntityOfPage":{"@id":"https://ubiq.online/blog/ubiq-and-ubiq-genie-tutorial-at-ieee-vr-2026/"},"datePublished":"2026-01-05T09:19:42CET","dateModified":"2026-02-04T19:40:18CET","author":{"@id":"https://ubiq.online/#/schema/person/2"},"publisher":{"@id":"https://ubiq.online/#/schema/organization/1"},"image":{"@id":"https://ubiq.online/blog/ubiq-and-ubiq-genie-tutorial-at-ieee-vr-2026/#/schema/image/2"}}]},{"@context":"https://schema.org","@graph":[{"@type":"Person","@id":"https://ubiq.online/#/schema/person/2","name":"Nels Numan","sameAs":[]}]},{"@context":"https://schema.org","@graph":[{"@type":"ImageObject","@id":"https://ubiq.online/blog/ubiq-and-ubiq-genie-tutorial-at-ieee-vr-2026/#/schema/image/2","url":null,"contentUrl":null,"width":1826,"height":874,"caption":"Ubiq and Ubiq-Genie Tutorial at IEEE VR 2026"}]}]}</script><meta name=theme-color content="#fff"><link rel=apple-touch-icon sizes=180x180 href=https://ubiq.online/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=https://ubiq.online/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=https://ubiq.online/favicon-16x16.png><link rel=manifest href=https://ubiq.online/site.webmanifest></head><body class="single section blog"><div class=header-bar></div><header class="navbar navbar-expand-md navbar-light doks-navbar"><nav class="container-xxl flex-wrap flex-md-nowrap" aria-label="Main navigation"><a class="navbar-brand p-0 me-auto" href=/ aria-label=Bootstrap>Ubiq</a>
<button class="btn btn-menu d-block d-md-none order-5" type=button data-bs-toggle=offcanvas data-bs-target=#offcanvasDoks aria-controls=offcanvasDoks aria-label="Open main menu"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"><line x1="3" y1="12" x2="21" y2="12"/><line x1="3" y1="6" x2="21" y2="6"/><line x1="3" y1="18" x2="21" y2="18"/></svg></button><div class="offcanvas offcanvas-start border-0 py-md-1" tabindex=-1 id=offcanvasDoks data-bs-backdrop=true aria-labelledby=offcanvasDoksLabel><div class="header-bar d-md-none"></div><div class="offcanvas-header d-md-none"><h2 class="h5 offcanvas-title ps-2" id=offcanvasDoksLabel><a class=text-dark href=/>Ubiq</a></h2><button type=button class="btn-close text-reset me-2" data-bs-dismiss=offcanvas aria-label="Close main menu"></button></div><div class="offcanvas-body px-4"><h3 class="h6 text-uppercase mb-3 d-md-none">Main</h3><ul class="nav flex-column flex-md-row ms-md-n3"><li class=nav-item><a class="nav-link ps-0 py-1" href=https://ucl-vr.github.io/ubiq/>Docs</a></li><li class=nav-item><a class="nav-link ps-0 py-1" href=/showcase/>Showcase</a></li><li class=nav-item><a class="nav-link ps-0 py-1 active" href=/blog/>Blog</a></li><li class=nav-item><a class="nav-link ps-0 py-1" href=/publication/>Publications</a></li><li class=nav-item><a class="nav-link ps-0 py-1" href=/teaching>Teaching</a></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle ps-0 py-1" href=# id=navbarDropdownMenuLink role=button data-bs-toggle=dropdown aria-expanded=false>Contact
<span class=dropdown-caret><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-down"><polyline points="6 9 12 15 18 9"/></svg></span></a><ul class="dropdown-menu dropdown-menu-main shadow rounded border-0" aria-labelledby=navbarDropdownMenuLink><li><a class=dropdown-item href=https://github.com/UCL-VR/ubiq/discussions/categories/q-a>â†— Ask a Question</a></li><li><a class=dropdown-item href=/contributors/>Contributors</a></li><li><a class=dropdown-item href=/media/>Media</a></li></ul></li></ul><hr class="text-black-50 my-4 d-md-none"><h3 class="h6 text-uppercase mb-3 d-md-none">Socials</h3><ul class="nav flex-column flex-md-row ms-md-auto me-md-n5 pe-md-2"><li class=nav-item><a class="nav-link ps-0 py-1" href=https://discord.gg/cZYzdcxAAB><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 128 128" fill="#000" stroke="currentcolor" stroke-width="5" stroke-linecap="round" stroke-linejoin="round" class="feather feather-discord"><path d="M45.23 57.2c-6.16.0-11.17 5.6-11.17 12.48s5 12.47 11.17 12.47 11.16-5.59 11.16-12.47S51.38 57.2 45.23 57.2zm0 21c-4 0-7.17-3.8-7.17-8.47s3.21-8.48 7.17-8.48 7.16 3.8 7.16 8.48-3.21 8.42-7.16 8.42z"/><path d="M121.83 59.58a156.78 156.78.0 00-11.52-31 2.1 2.1.0 00-.71-.77 87.08 87.08.0 00-15.23-7.17C84.55 17.07 79.91 17 79.72 17a2 2 0 00-2 1.72l-.6 4.17a133.14 133.14.0 00-26.28.0l-.6-4.17a2 2 0 00-2-1.72c-.19.0-4.83.0-14.65 3.61A87.08 87.08.0 0018.4 27.81a2.1 2.1.0 00-.71.77 156.72 156.72.0 00-11.52 31C1 80.46.0 90.91.0 91.34a2 2 0 00.49 1.5 55.2 55.2.0 0018.2 12.74A76.32 76.32.0 0038.48 111a2 2 0 001.92-1l5.4-9.25A105.08 105.08.0 0064 102.24a105.08 105.08.0 0018.2-1.51L87.6 110a2 2 0 001.72 1h.2a76.32 76.32.0 0019.78-5.38 55.2 55.2.0 0018.2-12.74 2 2 0 00.49-1.5C128 90.91 127.05 80.46 121.83 59.58zm-14.06 42.31a76.76 76.76.0 01-17.39 4.92l-4.08-7c4.68-1.24 14.42-4.46 21.83-11.2a2 2 0 10-2.69-3c-9 8.23-22.46 10.84-22.6 10.87h-.06A96.59 96.59.0 0164 98.24a96.59 96.59.0 01-18.78-1.7h-.06c-.14.0-13.55-2.64-22.6-10.87a2 2 0 10-2.69 3c7.41 6.74 17.15 10 21.83 11.2l-4.08 7a76.08 76.08.0 01-17.39-4.92A52.24 52.24.0 014.08 90.8c.33-2.91 1.68-13.07 6-30.24A156.25 156.25.0 0121 30.92 88.17 88.17.0 0135 24.4a61.35 61.35.0 0111.58-3.19l.35 2.39c-4 1-13.85 3.86-21.65 9.53a2 2 0 102.36 3.23c8.82-6.41 21-9.06 21.86-9.25A118.4 118.4.0 0164 26.27a117.64 117.64.0 0114.51.84c.91.19 13 2.83 21.86 9.25a2 2 0 102.36-3.23c-7.8-5.67-17.61-8.52-21.65-9.53l.35-2.39A61.75 61.75.0 0193 24.4a88.17 88.17.0 0114 6.52 156.25 156.25.0 0111 29.64c4.29 17.17 5.64 27.33 6 30.24a52.24 52.24.0 01-16.23 11.09z"/><path d="M82.77 57.2c-6.15.0-11.16 5.6-11.16 12.48s5 12.47 11.16 12.47 11.17-5.59 11.17-12.47S88.93 57.2 82.77 57.2zm0 21c-4 0-7.16-3.8-7.16-8.47s3.21-8.48 7.16-8.48 7.17 3.8 7.17 8.48S86.73 78.15 82.77 78.15z"/></svg><small class="ms-2 d-md-none">Discord</small></a></li><li class=nav-item><a class="nav-link ps-0 py-1" href=https://github.com/UCL-VR/ubiq/><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-github"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg><small class="ms-2 d-md-none">GitHub</small></a></li></ul></div></div><button id=mode class="btn btn-link order-md-1" type=button aria-label="Toggle user interface mode">
<span class=toggle-dark><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-moon"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg></span><span class=toggle-light><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-sun"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></span></button></nav></header><div class="wrap container-xxl" role=document><div class=content><div class="row justify-content-center"><div class="col-md-12 col-lg-10 col-xl-8"><article><div class=blog-header><h1>Ubiq and Ubiq-Genie Tutorial at IEEE VR 2026</h1><p><small>Posted January 5, 2026 by <a class="stretched-link position-relative" href=/contributors/anthony-steed/>Anthony Steed</a>, <a class="stretched-link position-relative" href=/contributors/nels-numan/>Nels Numan</a>, <a class="stretched-link position-relative" href=/contributors/ruijun-phoenix-sun/>Ruijun (Phoenix) Sun</a>, <a class="stretched-link position-relative" href=/contributors/daniele-giunchi/>Daniele Giunchi</a>&nbsp;&dash;&nbsp;<strong>4&nbsp;min read</strong></small><p></div><p class=lead>Learn how to build your own social XR systems using Ubiq and then integrate AI systems with Ubiq-Genie at the IEEE Conference on Virtual Reality and 3D User Interfaces (IEEE VR) 2026!</p><div class="alert alert-info d-flex" role=alert><div class="flex-shrink-1 alert-icon"></div><div class=w-100>Full sets of slides and video of the tutorial will be available after
IEEE VR 2026.</div></div><h2 id=summary>Summary</h2><p>In this tutorial we will explore how to build a wide variety of collaborative extended reality (XR) systems using the Ubiq software and then extend them to support artificial-intelligence (AI) based processes using Ubiq-Genie. Ubiq is an open source platform. It is designed to be easily extensible. It enables development of applications or systems that would be difficult or time-consuming on commercial systems. Ubiq-Genie allows AI processes to be integrated in a distributed manner. The tutorial will start with basic concepts, but then explore how more complete demonstrations can be built using new features that have been built on Ubiq and Ubiq-Genie in the past couple of years</p><div class="alert alert-info d-flex" role=alert><div class="flex-shrink-1 alert-icon"></div><div class=w-100>For information on how to join the tutorial, please see the <strong>IEEE VR 2026</strong> <a href=https://ieeevr.org/2026/program/tutorials/3>tutorial page</a>. Time and location to be announced.</div></div><h2 id=background>Background</h2><p>One of the most promising applications of extended reality technologies are their use for remote collaboration. A very wide variety of social extended reality (SXR) applications are now available; from competitive games amongst small numbers of players; through to conference-like setups supporting hundreds of attendees. At the same time, there is a lot of interest in integrating artificial intelligence (AI)-based algorithms into XR scenes. AI systems can control virtual humans, help with scene generation and provide content for interactive scenarios.</p><p>Ubiq is an open source tool that allows developers to very quickly build SXR applications. While introductory tutorials have been given in the past, and are available online, this tutorial will explore some of the new capabilities of Ubiq that specifically support researchers and teachers that want to do more than just explore the basics. We will also discuss our Ubiq-Genie tool and demonstrate how it allows AI-based systems to be integrated in a distributed fashion alleviating XR clients from needing to support such systems.</p><p>The tutorial is backed up by extensive online documentation, other explanatory videos and a growing set of more complex example systems.</p><h2 id=intended-audience-and-technical-level>Intended Audience and Technical Level</h2><p>The tutorial will be of value to any student, researcher or professional who wants to develop their own SXR application and is interested in using AI systems. They probably want to get a grounding in what the challenges are in building more complex systems. Some experience with Unity, C# and Python would be useful but not necessary as the scenarios will be walkthroughs of the components and tools rather than explicit code. Any code will be shared in an open repository. There will be additional online video tutorials and documentation if participants want to explore specific features.</p><h2 id=expected-value>Expected Value</h2><p>In this tutorial, participants will learn about SXR technologies and the capabilities of the Ubiq and Ubiq-Genie toolkits. We will give a short critique of alternate platforms.</p><h2 id=schedule>Schedule</h2><p>During the tutorial, the following topics will be covered.</p><table class=table-striped><thead><tr><th>Topic</th><th style=text-align:right>Start Time</th></tr></thead><tbody><tr><td>General Overview of Social XR & Generative AI Platforms (Steed)</td><td style=text-align:right>TBC</td></tr><tr><td>Overview of Ubiq (Steed)</td><td style=text-align:right>TBC+20</td></tr><tr><td>Overview of Ubiq-Genie (Sun, Numan & Giunchi)</td><td style=text-align:right>TBC+40</td></tr><tr><td>Wrap-Up and Q&A (All)</td><td style=text-align:right>TBC+80</td></tr></tbody></table><h2 id=slides>Slides</h2><p>To be added</p><h2 id=presenter-bios>Presenter Bios</h2><p><strong>Anthony Steed (Prof)</strong> is Head of the Virtual Environments and Computer Graphics group in the Department of Computer Science at University College London. He has over 25 years' experience in developing effective immersive experiences. While his early work focussed on the engineering of displays and software, more recently it has focussed on user engagement in collaborative and telepresent scenarios. He received the IEEE VGTC&rsquo;s 2016 Virtual Reality Technical Achievement Award.</p><p><strong>Ruijun (Phoenix) Sun</strong> is a second year Ph.D. student with the VECG group at UCL. He received an MEng in Computer Science, also from UCL. His PhD topic focuses on novel guardian systems and safety mechanisms in Virtual Reality. Ruijun&rsquo;s ongoing project is Dynamic VR safety system using object detection, which is based on OpenVR overlay, ubiq-genie and computer vision to provide real-time detection of dynamic obstacles with the ability to run simultaneously with commercial VR applications.</p><p><strong>Nels Numan</strong> is a PhD candidate in the Virtual Environments and Computer Graphics group in the Department of Computer Science at University College London. His research examines interpersonal and human-AI collaboration in mixed reality, with an emphasis on computationally parsing, representing, and transforming spatial environments to support situated action and shared understanding. During his doctoral studies, he has completed research internships at Google, Niantic Labs, and Microsoft Research. He holds BSc and MSc degrees in Computer Science and has served as a web chair for IEEE VR and IEEE ISMAR.</p><p><strong>Daniele Giunchi</strong> is an Assistant Professor in Scene Understanding and Smart Environments at the University of Birmingham and an Honorary Lecturer at University College London. His research sits at the intersection of HCI, extended reality (XR), computer vision, and intelligent systems, with a focus on multimodal (e.g., speech/gesture/gaze) and advanced interaction, and on integrating AI/LLM-driven processes into collaborative XR. He contributes to the open-source Ubiq ecosystem and has worked on AI-supported behavior design and collaboration in social XR.</p></article></div></div></div></div><section class="section section-sm mt-n5 mb-3"><div class=container><div class="row justify-content-center"><div class="col-md-12 col-lg-10 col-xl-8"></div></div></div></section><footer class="footer text-muted"><div class=container-xxl><div class=row><div class="col-lg-8 order-last order-lg-first"><ul class=list-inline><li class=list-inline-item></li></ul></div><div class="col-lg-8 order-first order-lg-last text-lg-end"><ul class=list-inline><li class=list-inline-item><a href=/privacy-policy/>Privacy</a></li></ul></div></div></div></footer><script data-goatcounter=https://ubiq.goatcounter.com/count async src=//gc.zgo.at/count.js></script>
<script src=/js/bootstrap.min.fdbe9b9ba88a036135318f3c721784d684ac9e3280fe282cc80d7d49f7f9c82780cd54228c1608685a230c09984300d7946fc471734d566fcebc148b65bd16db.js integrity="sha512-/b6bm6iKA2E1MY88cheE1oSsnjKA/igsyA19Sff5yCeAzVQijBYIaFojDAmYQwDXlG/EcXNNVm/OvBSLZb0W2w==" crossorigin=anonymous defer></script>
<script src=/js/highlight.min.2a3ca603c4e5468838fb437bc036b9ddc036b6668b5dd45804f048229ea684f98f5928dd485b41db90e55aaa28b36600341f082d2726650a0a394250b6bf3ac1.js integrity="sha512-KjymA8TlRog4+0N7wDa53cA2tmaLXdRYBPBIIp6mhPmPWSjdSFtB25DlWqoos2YANB8ILScmZQoKOUJQtr86wQ==" crossorigin=anonymous defer></script>
<script src=/main.min.7692813ef22de5d343339990192d5774c0742a9334f8f57bb78245f5ab0e02861e3e47e7308e649ca0173ef9e307477de2769299fdb90a9e4a5e327df94553b7.js integrity="sha512-dpKBPvIt5dNDM5mQGS1XdMB0KpM0+PV7t4JF9asOAoYePkfnMI5knKAXPvnjB0d94naSmf25Cp5KXjJ9+UVTtw==" crossorigin=anonymous defer></script></body></html>