---
title: "Ubiq Tutorial at IEEE VR 2025"
description: "Schedule and instructions for the Ubiq tutorial at IEEE VR 2025."
lead: "Learn how to build your own social extended virtual reality with Ubiq at the IEEE Conference on Virtual Reality and 3D User Interfaces (IEEE VR) 2025!"
date: 2025-03-05T09:19:42+01:00
lastmod: 2025-03-05T09:19:42+01:00
draft: false
weight: 50
images: []
contributors: ["Anthony Steed", "Ben Congdon", "Jingyi Zhang", "Ruijun (Phoenix) Sun"]
---

{{< alert context="info" >}}

Full sets of slides and video of the tutorial will be available after
IEEE VR 2025.

{{< /alert >}}

## Summary

In this tutorial we will explore how to build a wide variety of collaborative extended reality (XR) systems using the Ubiq software. Ubiq is an open source platform. It is designed to be easily extensible. It enables development of applications or systems that would be difficult or time-consuming on commercial systems. The tutorial will start with basic concepts, but then explore how more complete demonstrations can be built using new features that have been built on Ubiq in the past couple of years.

{{< alert context="info" >}}

For information on how to join the tutorial, please see the **IEEE VR 2025** [tutorial page](https://ieeevr.org/2025/program/tutorials/#T3). We are currently scheduled for Saturday, March 8, 2025, 10:45:00-12:30:00 (Saint-Malo France UTC+1) Room: Vauban 1


{{< /alert >}}

## Background

One of the most promising applications of extended reality technologies are their use for remote collaboration. A very wide variety of social extended reality (SXR) applications are now available; from competitive games amongst small numbers of players; through to conference-like setups supporting hundreds of attendees.

Ubiq is an open source tool that allows developers to very quickly build SXR applications. While introductory tutorials have been given in the past, and are available online, this tutorial will explore some of the new capabilities of Ubiq that specifically support researchers and teachers that want to do more than just explore the basics. We will start from first principles and explore some of the main architectural decisions. Then we will work through a series of scenarios that explore more interesting demonstrations. We propose to do this in a novel "How Do I?" format where we will solicit requirements and ideas from the audience prior to and during the session. We will then demonstrate how these might be implemented, drawing on the work of our team and other users who have shared demonstrations.

The tutorial is backed up by extensive online documentation, other explanatory videos and a growing set of more complex example systems.





## Intended Audience and Technical Level

 The tutorial will be of value to any student, researcher or professional who wants to develop their own SXR application. They probably want to get a grounding in what the challenges are in building more complex systems. Some experience with Unity would be useful but not necessary as the scenarios will be walkthroughs of the components and tools rather than explicit code. Any code will be shared in an open repository. There will be additional online video tutorials and documentation if participants want to explore specific features.

## Expected Value

In this tutorial, participants will learn about SXR technologies and the capabilities of the Ubiq toolkit. We will give a short critique of the various commercial platforms. With the "How Do I?" session participants can get an outline and possibly even a short demonstration of how their scenario or idea might be implemented. 

## Schedule

During the tutorial, the following topics will be covered. 

{ .table-striped }
| Topic                                                   | Start Time                       |
|---------------------------------------------------------|---------------------------------:|
| General Overview of Social VR Platforms (Steed)         |                    10:45 |
| Overview of Ubiq (Congdon)                  |                    11:15 |
| Recent Demonstrations (All)         |                    11:45 |
| How Do I? (All)                                    |                    12:00 |
| Q&A (All)                                    |                    12:20 |
{ .table-striped }

## Slides

To be added

## Presenter Bios

**Anthony Steed (Prof)** is Head of the Virtual Environments and Computer Graphics group in the Department of Computer Science at University College London. He has over 25 years’ experience in developing effective immersive experiences. While his early work focussed on the engineering of displays and software, more recently it has focussed on user engagement in collaborative and telepresent scenarios. He received the IEEE VGTC’s 2016 Virtual Reality Technical Achievement Award.  Recently he was a Visiting Researcher at Microsoft Research, Redmond and an Erskine Fellow at the Human Interface Technology Laboratory in Christchurch, New Zealand.

**Ben Congdon (Dr)** is a research associate with the VECG group at UCL. He received an MEng in Computer Science, also from UCL. His PhD topic was redirected walking in obstacle-rich virtual environments. Ben has worked as a software engineer in Formula One and a researcher in telecommunications. His current work is on open-source software to improve access to mixed reality development.