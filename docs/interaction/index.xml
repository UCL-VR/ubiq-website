<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Interaction on</title><link>https://ucl-vr.github.io/ubiq-website/docs/interaction/</link><description>Recent content in Interaction on</description><generator>Hugo -- gohugo.io</generator><language>en-US</language><lastBuildDate>Tue, 06 Oct 2020 08:48:45 +0000</lastBuildDate><atom:link href="https://ucl-vr.github.io/ubiq-website/docs/interaction/index.xml" rel="self" type="application/rss+xml"/><item><title>XR Interaction</title><link>https://ucl-vr.github.io/ubiq-website/docs/interaction/interaction/</link><pubDate>Tue, 13 Oct 2020 15:21:01 +0200</pubDate><guid>https://ucl-vr.github.io/ubiq-website/docs/interaction/interaction/</guid><description>Ubiq includes a straightforward XR interaction framework. This supports high level actions such as Using and Grasping 2D and 3D objects, as well as interacting with the Unity UI system.
Ubiq is not dependent on its own interaction system, and it is expected users may utilise the Unity XR Interaction Toolkit, MRTK, VRTK or another system for advanced functionality.
The Ubiq system is intended to support common XR requirements however, while being very simple to use, and transparently cross-platform.</description></item><item><title>3D Interaction</title><link>https://ucl-vr.github.io/ubiq-website/docs/interaction/3dinteraction/</link><pubDate>Tue, 13 Oct 2020 15:21:01 +0200</pubDate><guid>https://ucl-vr.github.io/ubiq-website/docs/interaction/3dinteraction/</guid><description>Interacting with 3D objects is action based. Users can Use or Grasp objects. What these actions do is entirely up to user code.
For example, users could Use a button which spawns an object or turns on a light. They could Grasp a box which attaches to their hand, or a door which swings around an axis.
To implement these behaviours, Components implement IUsable or IGraspable. They will then recieve callbacks to Use()/UnUse() and Grasp()/Release(), respectively.</description></item><item><title>2D Interaction</title><link>https://ucl-vr.github.io/ubiq-website/docs/interaction/2dinteraction/</link><pubDate>Tue, 13 Oct 2020 15:21:01 +0200</pubDate><guid>https://ucl-vr.github.io/ubiq-website/docs/interaction/2dinteraction/</guid><description>The Ubiq XR interaction integrates with Unity&amp;rsquo;s UI system. Players can raycast from their hands to interact with Unity Canvases and controls.
To enable Ubiq XR interaction with a Canvas, add the XRUICanvas component to it. Once this Component is added users can interact with the Unity controls using raycasts from the controllers, or the mouse cursor on the desktop.
When using the XRUICanvas an EventSystem is no longer required. Cameras are not required either on World Space Canvases, allowing them to be declared in Prefabs and instantiated dynamically.</description></item><item><title>Player Controller</title><link>https://ucl-vr.github.io/ubiq-website/docs/interaction/playercontroller/</link><pubDate>Tue, 13 Oct 2020 15:21:01 +0200</pubDate><guid>https://ucl-vr.github.io/ubiq-website/docs/interaction/playercontroller/</guid><description>Users move through the world using Player Controllers. The Samples contain a Player Prefab with a camera and two hands. Player Controllers can move linearly or teleport. Interaction always occurs through a Hand instance, so a Player Controller is not technically necessary.</description></item></channel></rss>